
### 6. Tenemos un multiconjunto $B$ de valores de billetes y queremos comprar un producto de costo $c$ de una máquina que no da vuelto. Para poder adquirir el producto debemos cubrir su costo usando un subconjunto de nuestros billetes. El objetivo es pagar con el mínimo exceso posible a fin de minimizar nuestra pérdida. Más aún, queremos gastar el menor tiempo posible poniendo billetes en la máquina. Por lo tanto, entre las opciones de mínimo exceso posible, queremos una con la menor cantidad de billetes. Por ejemplo, si $c = 14$ y $B = \{2,\ 3,\ 5,\ 10,\ 20,\ 20\}$, la solución es pagar $15$, con exceso $1$, insertando sólo dos billetes: uno de $10$ y otro de $5$.


<br>

### (a) Considerar la siguiente estrategia por backtracking para el problema, donde $B = \{b_1\ . . .\ b_n\}$. Tenemos dos posibilidades: o agregamos el billete $b_n$, gastando un billete y quedando por pagar $c − b_n$, o no agregamos el billete $b_n$, gastando $0$ billetes y quedando por pagar $c$. Escribir una función recursiva $cc(B, c)$ para resolver el problema, donde $cc(B, c) = (c', q)$ cuando el mínimo costo mayor o igual a $c$ que es posible pagar con los billetes de $B$ es $c'$ y la cantidad de billetes mínima es $q$.

\
Sea $B := \{b_1\ ...\ b_n\}$ un multiconjunto de naturales y $c \in \mathbb{R}_{\geq 0}$ tal que $\sum_{i=1}^n b_i \geq c$. Definimos la función

$\begin{align}\nonumber
    cc(\{b_1\ ...\ b_n\},\ c) = 
        \begin{cases}
            (0,\ 0) & n = 0\\
            q + (b_n,\ 1) & n> 0\ \wedge\ c > \sum_{i=1}^{n-1} b_i\\
            \min\{p,\ q + (b_n,\ 1)\} & \text{si no}
        \end{cases}
\end{align}$

donde $p := cc(\{b_1\ ...\ b_{n-1}\},\ c)$, $q := cc(\{b_1\ ...\ b_{n-1}\},\ c - b_n)$ y la función $\min$ depende de la prioridad que le querramos dar a cada restricción.

Vamos a probar por inducción sobre $n \in \mathbb{N}_0$ que la función soluciona el problema.

Para el caso base, $n = 0$, notemos primero que tanto la cantidad de billetes a utilizar como el exceso a pagar son necesariamente valores no negativos. Entonces, dado que $c \leq \sum_{i=1}^0 b_i = 0$, la solución debe ser $(0, 0)$. Sigue que $cc(\{\},\ c)$ resuelve el problema.

Para el paso inductivo, supongamos que $cc(\{b_1\ ...\ b_k\},\ w)$ resuelve el problema para todo $w \in \mathbb{R}_{\geq0}$ tal que $\sum_{i=1}^k b_i \geq w$. Consideremos $cc(\{b_1\ ...\ b_{k+1}\},\ c)$. 

Si $c > \sum_{i=1}^{k} b_i$, entonces $cc(\{b_1\ ...\ b_{k}\},\ c)$ no tiene solución. Esto quiere decir que una solución de $cc(\{b_1\ ...\ b_{k+1}\},\ c)$ tendrá que utilizar, necesariamente, a $b_{k+1}$. Dado que $\sum_{i=1}^{k+1} b_i \geq c$ implica que $\sum_{i=1}^{k} b_i \geq c - b_{k+1}$, entonces $cc(\{b_1\ ...\ b_{k}\},\ c - b_{k+1})$ tiene solución. Por hipótesis inductiva, su resultado será la tupla $(d,\ r)$ que minimice los billetes utilizados y el exceso pagado para la instancia $\{b_1\ ...\ b_k\},\ c - b_{k+1}$. Por el principio de optimalidad, sigue que la solución óptima para nuestro problema será $(d,\ r)$ más el costo de incluir a $b_{k+1}$ en la solución. Esto es, $cc(\{b_1\ ...\ b_{k}\},\ c - b_{k+1}) + (b_{k+1},\ 1)$. Equivalentemente, $cc(\{b_1\ ...\ b_{k+1}\},\ c)$.

En cambio, si $c \leq \sum_{i=1}^{k} b_i$, sigue que podemos elegir tomar, o no, al elemento $b_{k+1}$, ya que ambas opciones resultan en un subproblema válido. Entonces, nuevamente por hipótesis inductiva y el principio de optimalidad, la solución a $cc(\{b_1\ ...\ b_{k+1}\},\ c)$ será el mínimo entre ambas posibilidades: $cc(\{b_1\ ...\ b_{k}\},\ c)$ y $cc(\{b_1\ ...\ b_{k}\},\ c - b_{k+1}) + (b_{k+1},\ 1)$. Esto es, $cc(\{b_1\ ...\ b_{k+1}\},\ c)$. 
 
$\blacksquare$


<br>

### (b) Implementar la función de (a) en un lenguaje de programación imperativo utilizando una función recursiva con parámetros $B,\ i,\ j$ que compute $cc(\{b_1\ . . .\ b_i\}, j)$. ¿Cuál es la complejidad del algoritmo?

\
Podemos considerar, de manera ingenua, el siguiente algoritmo.

```
cc(B, i, j):
    si i = 0:
        retornar (0, 0)
    si j > sum(B, i - 1):
        retornar cc(B, i-1, j-B[i]) + (B[i], 1)
    sino:
        retornar min(cc(B, i-1, j),
                     cc(B, i-1, j-B[i]) + (B[i], 1))
```

Respecto a la complejidad, vemos que esta se puede definir por medio de la recurrencia

$\begin{align}\nonumber
    t_0 &= c_1 \\\nonumber
    t_i &= 2 \cdot t_{i - 1} + O(n)    
\end{align}$

donde $c_1$ es una constante. Se puede demostrar por inducción que $t_i \in O(i2^i)$.

Sin embargo, si relajamos las restricciones del dominio para las sub-instancias, podemos lograr una mejor complejidad de la siguiente forma.

```
cc(B, i, j):
    si i = 0:
        si j > 0:
            retornar (∞, ∞)
        sino:
            retornar (0, 0)
    sino:
        retornar min(cc(B, i-1, j),
                     cc(B, i-1, j-B[i]) + (B[i], 1))
```
Ya que, si $i > 0$ y $j > \sum_{k=1}^{i-1} b_k$, la instancia con parámteros $B,\ i-1,\ j$ retornará $(\infty,\ \infty)$ (esto se puede demostrar por inducción). En consecuencia, la instancia $B,\ i,\ j$ elegirá a `cc(B, i-1, j-B[i]) + (B[i], 1)` al computar el mínimo, tal como en la propuesta anterior.

En este caso, la complejidad queda definida por la relación de recurrencia

$\begin{align}\nonumber
    t_0 &= c_1 \\\nonumber
    t_i &= 2 \cdot t_{i - 1} + c_2
\end{align}$

donde $c_1$ y $c_2$ son constantes. Entonces, $t_i \in O(2^i)$.

$\blacksquare$


<br>

### (c) Reescribir $cc$ como una función recursiva $cc'_B (i,\ j) = cc(\{b_1\ . . .\ b_i\},\ j)$ que implemente la idea anterior dejando fijo el parámetro $B$. A partir de esta función, determinar cuándo $cc'_B$ tiene la propiedad de superposición de subproblemas.

\
De manera análoga a la parte (a), sea $B := \{b_1\ ...\ b_n\}$ un multiconjunto de naturales y $c \in \mathbb{R}_{\geq 0}$ tal que $\sum_{i=1}^n b_i \geq c$. Definimos la función

$\begin{align}\nonumber
    cc'_B(n,\ c) = 
        \begin{cases}
            (0,\ 0) & n = 0\\
            q + (b_n,\ 1) & n> 0\ \wedge\ c > \sum_{i=1}^{n-1} b_i\\
            \min\{p,\ q + (b_n,\ 1)\} & \text{si no}
        \end{cases}
\end{align}$

donde $p := cc'_B(n - 1,\ c)$, $q := cc'_B(n - 1,\ c - b_n)$ y la función $\min$ depende de la prioridad que le querramos dar a cada restricción.

Se puede demostrar que esta función es equivalente a la anterior de manera análoga a la demostración de la parte (a) del [Ejercicio 1.5](1.05.md).

Está claro que las llamadas recursivas del tercer caso de $cc'_B$ tienen la propiedad de superposición de subproblemas.

$\blacksquare$


<br>

### (d) Definir una estructura de memoización para $cc'_B$ que permita acceder a $cc'_B(i,\ j)$ en $O(1)$ tiempo para todo $0 \leq i \leq n$ y $0 \leq j \leq k$.

\
Por combinatoria, tenemos $(n + 1)\cdot(k + 1)$ entradas posibles para $cc'_B$. Sigue que una matriz $M$ de dimensiones $(n + 1)\times(k + 1)$ será suficiente para acceder en tiempo constante a cualquier resultado posible de la función. Es decir, si $M$ es tal que

$\begin{align}\nonumber
    M_{ij} = cc'_B(i,\ j)
\end{align}$

para todo $0 \leq i \leq n$ y $0 \leq j \leq k$, entonces $M$ es una estructura de memoización para $cc'_B$.

$\blacksquare$


<br>

### (e) Adaptar el algoritmo de (b) para incluir la estructura de memoización.

\
Podemos considerar

```
inicializar M[i, j] = ⊥ para todo 0 <= i <= n y 0 <= j <= k.
cc(B, i, j):
    si j <= 0:
        retornar (0, 0)
    si i = 0 y j > 0:
        retornar (∞, ∞)
    si M[i, j] = ⊥:
        M[i, j] = min(cc(B, i-1, j),
                      cc(B, i-1, j-B[i]) + (B[i], 1))
    retornar M[i, j]
```

$\blacksquare$


<br>

### (f) Indicar cuál es la llamada recursiva que resuelve nuestro problema y cuál es la complejidad del nuevo algoritmo.

\
La llamada recursiva ocurre en la asignación de $M_{ij}$ en la línea 9.

Dada la estructura de memoización, el valor de $M_{ij}$ será indefinido en a lo sumo $O(nk)$ llamados recursivos, mientras que en el resto, la función se resolverá en tiempo constante. En consecuencia, la complejidad temporal tendrá un peor caso en $O(nk)$.

$\blacksquare$


<br>

### (g) (Opcional) Escribir un algoritmo bottom-up para calcular todos los valores de la estructura de memoización y discutir cómo se puede reducir la memoria extra consumida por el algoritmo.

\
Podemos considerar

```
cc(B, k):
    n = |B|
    M = matriz de tamaño n x k
    M[0, 0] = (0, 0)
    Para j = 1 ... k:
        M[0, j] = (∞, ∞)
    Para i = 1 ... n y para j = 0 ... k:
        si j-B[i] >= 0:
            r = M[i-1, j-B[i]]
        sino:
            r = (0, 0)
        M[i, j] = min(M[i-1, j], r + (B[i], 1))
    retornar M[n, k]
```

Del mismo modo que en la parte (f) del [Ejercicio 1.5](1.05.md), podemos reducir la memoria utilizada, resultando en el siguiente algoritmo

```
cc(B, k):
    n = |B|
    M = matriz de tamaño n x k   
    M[0] = (0, 0)
    Para j = 1 ... k:
        M[j] = (∞, ∞)
    Para i = 1 ... n y para j = 0 ... k:
        si j-B[i] > 0:
            r = M[j-B[i]]
        sino:
            r = (0, 0)
        M[j] = min(M[j], r + (B[i], 1))
    retornar M[k]
```


$\blacksquare$


<br>

### (h) (Opcional) Formalmente, en este problema de vuelto hay que computar el mínimo $(\sum V, |V|)$, en orden lexicográfico, de entre los conjuntos $V \subset B$ tales que $\sum V \geq c$. Demostrar que la función $cc'$ es correcta. Ayuda: demostrar por inducción que $cc'(i, j) = (v, k)$ para el mínimo $(v, k)$ tal que existe un subconjunto $V$ de $\{b_1\ . . .\ b_i\}$ con $\sum V \geq j$.

\
Dado que la función $cc'$ es equivalente a la función $cc$ y, por la demostración de la parte (a), ésta es correcta, sigue que $cc'$ también lo es.

$\blacksquare$
