### Se arrojan simultáneamente $n$ dados, cada uno con $k$ caras numeradas de $1$ a $k$. Queremos calcular todas las maneras posibles de conseguir la suma total $s \in \mathbb{N}$ con una sola tirada. Tomamos dos variantes de este problema: 

### A. Consideramos que los dados son distinguibles, es decir que si $n = 3$ y $k = 4$, entonces existen $10$ posibilidades que suman $s = 6$:

1. $4$ posibilidades en las que el primer dado vale $1$.
2. $3$ posibilidades en las que el primer dado vale $2$.
3. $2$ posibilidades en las que el primer dado vale $3$.
4. Una posibilidad en la que el primer dado vale $4$.

### B. Consideramos que los dados son indistinguibles, es decir que si $n = 3$ y $k = 4$, entonces existen $3$ posibilidades que suman $s = 6$:

1. Un dado vale $4$, los otros dos valen $1$.
2. Un dado vale $3$, otro $2$ y otro $1$.
3. Todos los dados valen $2$.


<br>

### (a) Definir en forma recursiva la función $f : \mathbb{N}^2 \to \mathbb{N}$ tal que $f(n, s)$ devuelve la respuesta para el escenario A (fijado $k$).

\
Podemos pensar la variante A del problema de la siguiente forma: la cantidad de maneras de  sumar $s$ a partir de $n$ dados con $k$ caras es igual a la sumatoria de la cantidad de maneras de sumar $s - l$, $1 \leq l \leq k$, con los $n - 1$ dados restantes. Es decir, contar la cantidad de formas de sumar $s$ si ya sabemos el valor de uno de los dados. Como ninguna cantidad de dados puede sumar un número negativo y existe una única forma de sumar $0$ con $0$ dados, sigue que 

$\begin{align}\nonumber
    f(i,\ j) =
        \begin{cases}
            0   & i = 0 \wedge j > 0 \\
            1   & i = 0 \wedge j = 0 \\
            \sum_{l=1}^{\min\{k,\ j\}}f(i - 1,\  j - l) &\text{si no}
        \end{cases}
\end{align}$

satisface que $f(n,\ s)$ es la solución del problema.

$\blacksquare$


<br>

### (b) Definir en forma recursiva la función $g : \mathbb{N}^3 \to \mathbb{N}$ tal que $g(n, s, k)$ devuelve la respuesta para el escenario B.

\
A diferencia de $f$, en este caso no nos interesa el orden en que un multiconjunto de caras (conjunto de dados) sume $s$. Una forma de lograr esto es que el algoritmo pueda construir una sola permutación posible de cada multiconjunto. Por ejemplo, la que ordena a sus miembros de mayor a menor. Entonces, podemos pensar la variante B del problema de la siguiente forma: la cantidad de maneras de  sumar $s$ a partir de $n$ dados con $k$ caras es igual a la sumatoria de la cantidad de maneras de sumar $s - l$, $1 \leq l \leq k$, con las primeras $l$ caras de los $n - 1$ dados restantes. Sigue que

$\begin{align}\nonumber
    g(i,\ j,\ r) =
        \begin{cases}
            0   & i = 0 \wedge j > 0 \\
            1   & i = 0 \wedge j = 0 \\
            \sum_{l=1}^{\min\{r,\ j\}}g(i - 1,\  j - l,\ l) &\text{si no}
        \end{cases}
\end{align}$

satisface que $g(n,\ s,\ k)$ es la solución del problema.

$\blacksquare$


<br>

### (c) Demostrar que $f$ y $g$ poseen la propiedad de superposición de subproblemas.

\
Dado que las entradas de $f$ son los valores $i,\ j$ que satisfacen $0 \leq i \leq n$ y $0 \leq j \leq s$, sigue que hay $O(ns)$ entradas posibles para la función. Sin embargo, es fácil ver que el algoritmo realiza, en el peor caso, $O(k^n)$ llamadas recursivas. Por el principio de las cajas, sigue que, si $s < {k^n}/{n}$, debe haber superposición de problemas.

Respecto a $g$, vemos que las entradas posibles son los valores $i,\ j,\ r$ que satisfacen $0 \leq i \leq n$, $0 \leq j \leq s$ y $1 \leq r \leq k$. Sigue que hay $O(nks)$ entradas posibles. De manera similar al caso anterior, si $s < k^{n-1}/n$, entonces hay superposición de problemas.

Si no, es fácil ver que la estructura misma del problema nos lleva a considerar los mismos subproblemas. Por ejemplo si consideramos $k = 4$, entonces $f(3, 5)$ llama, entre otros, a $f(2, 3)$ y $f(2, 4)$ y, a su vez, ambos llaman a $f(1, 0),\ f(1, 1),\ f(1, 2)$ y $f(1, 3)$.

En tanto lo que respecta un algoritmo de programación dinámica, observamos también lo siguiente: como la suma máxima de $n$ dados con $k$ caras es $nk$, sigue que sólo vale la pena considerar el problema para $s \leq nk$. Si no, la respuesta es $0$.


$\blacksquare$


<br>

### (d) Definir algoritmos top-down para calcular $f(n, s)$ y $g(n, s, k)$ indicando claramente las estructuras de datos utilizadas y la complejidad resultante.

\
Podemos implementar la lógica de tanto $f$ como $g$ con una matriz $M$ de tamaño $n \times \min\{s,\ nk\}$. 

Como se realizarán a lo sumo $n\min\{s,\ nk\}$ llamados recursivos antes de definir todas las posiciones en $M$, y la suma de los $k$ subproblemas toma tiempo en $O(k)$ si los mismos se encuentran en $M$, sigue que un algoritmo de programación dinámica para cualquiera de las dos variantes va a tener una complejidad temporal de peor caso en $O(nk\min\{s,\ nk\})$. 

En tanto su complejidad espacial, esta será $O(n\min\{s,\ nk\})$, por el coste de $M$ y el espacio constante de un stack de $n\min\{s,\ nk\}$ llamadas en el peor caso.

La definición exacta de ambos algoritmos se puede ver en la parte (e).

$\blacksquare$


<br>

### (e) Escribir el (pseudo)código de los algoritmos top-down resultantes.

\
Dadas las observaciones de los puntos anteriores, un algoritmo top-down para $f$ podría ser el siguiente

```
Inicializar M[i, j] = ⊥ para 1 <= i <= n y 1 <= j <= min(s, nk)
proc f(i, j):
    si j > min(s, nk):
        retornar 0
    si i = 0:
        si j > 0:
            retornar 0
        sino:
            retornar 1
    si M[i, j] = ⊥:
        M[i, j] = sumar f(i-1, j-l) para todo 1 <= l <= min(k, j)
    retornar M[i, j]
```

Mientras que un algoritmo top-down para $g$ podría ser

```
Inicializar M[i, j] = ⊥ para 1 <= i <= n y 1 <= j <= min(s, nk)
proc g(i, j, r):
    si j > min(s, nk):
        retornar 0
    si i = 0:
        si j > 0:
            retornar 0
        sino:
            retornar 1
    si M[i, j] = ⊥:
        M[i, j] = sumar f(i-1, j-l) para todo 1 <= l <= min(r, j)
    retornar M[i, j]
```


$\blacksquare$


<br>

### Nota: Una solución correcta de este ejercicio debería indicar cómo se computa tanto $f(n, s)$ como $g(n, s, k)$ en tiempo $O(nk \min\{s, nk\})$.
